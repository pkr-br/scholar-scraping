{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c5d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: selenium in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 2)) (3.141.0)\n",
      "Requirement already satisfied: google-api-python-client in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 3)) (2.108.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 4)) (0.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: firebase_admin in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 6)) (6.2.0)\n",
      "Requirement already satisfied: chromedriver-autoinstaller-fix in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 7)) (1.0.3)\n",
      "Requirement already satisfied: PyGithub in d:\\anaconda\\lib\\site-packages (from -r requirements.txt (line 8)) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: urllib3 in d:\\anaconda\\lib\\site-packages (from selenium->-r requirements.txt (line 2)) (1.26.16)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in d:\\anaconda\\lib\\site-packages (from google-api-python-client->-r requirements.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in d:\\anaconda\\lib\\site-packages (from google-api-python-client->-r requirements.txt (line 3)) (2.23.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in d:\\anaconda\\lib\\site-packages (from google-api-python-client->-r requirements.txt (line 3)) (2.14.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\anaconda\\lib\\site-packages (from google-api-python-client->-r requirements.txt (line 3)) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda\\lib\\site-packages (from google-auth-oauthlib->-r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: cachecontrol>=0.12.6 in d:\\anaconda\\lib\\site-packages (from firebase_admin->-r requirements.txt (line 6)) (0.13.1)\n",
      "Requirement already satisfied: google-cloud-storage>=1.37.1 in d:\\anaconda\\lib\\site-packages (from firebase_admin->-r requirements.txt (line 6)) (2.13.0)\n",
      "Requirement already satisfied: pyjwt[crypto]>=2.5.0 in d:\\anaconda\\lib\\site-packages (from firebase_admin->-r requirements.txt (line 6)) (2.8.0)\n",
      "Requirement already satisfied: google-cloud-firestore>=2.9.1 in d:\\anaconda\\lib\\site-packages (from firebase_admin->-r requirements.txt (line 6)) (2.13.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from chromedriver-autoinstaller-fix->-r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from chromedriver-autoinstaller-fix->-r requirements.txt (line 7)) (23.1)\n",
      "Requirement already satisfied: pynacl>=1.4.0 in d:\\anaconda\\lib\\site-packages (from PyGithub->-r requirements.txt (line 8)) (1.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\anaconda\\lib\\site-packages (from PyGithub->-r requirements.txt (line 8)) (4.7.1)\n",
      "Requirement already satisfied: Deprecated in d:\\anaconda\\lib\\site-packages (from PyGithub->-r requirements.txt (line 8)) (1.2.14)\n",
      "Requirement already satisfied: msgpack>=0.5.2 in d:\\anaconda\\lib\\site-packages (from cachecontrol>=0.12.6->firebase_admin->-r requirements.txt (line 6)) (1.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\anaconda\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (1.61.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in d:\\anaconda\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (4.25.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\anaconda\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (1.59.3)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\anaconda\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client->-r requirements.txt (line 3)) (1.59.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client->-r requirements.txt (line 3)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client->-r requirements.txt (line 3)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in d:\\anaconda\\lib\\site-packages (from google-cloud-firestore>=2.9.1->firebase_admin->-r requirements.txt (line 6)) (2.3.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in d:\\anaconda\\lib\\site-packages (from google-cloud-firestore>=2.9.1->firebase_admin->-r requirements.txt (line 6)) (1.22.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in d:\\anaconda\\lib\\site-packages (from google-cloud-storage>=1.37.1->firebase_admin->-r requirements.txt (line 6)) (2.6.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in d:\\anaconda\\lib\\site-packages (from google-cloud-storage>=1.37.1->firebase_admin->-r requirements.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\anaconda\\lib\\site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in d:\\anaconda\\lib\\site-packages (from pyjwt[crypto]>=2.5.0->firebase_admin->-r requirements.txt (line 6)) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.4.1 in d:\\anaconda\\lib\\site-packages (from pynacl>=1.4.0->PyGithub->-r requirements.txt (line 8)) (1.15.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->chromedriver-autoinstaller-fix->-r requirements.txt (line 7)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->chromedriver-autoinstaller-fix->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->chromedriver-autoinstaller-fix->-r requirements.txt (line 7)) (2023.7.22)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->-r requirements.txt (line 5)) (3.2.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\anaconda\\lib\\site-packages (from Deprecated->PyGithub->-r requirements.txt (line 8)) (1.14.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub->-r requirements.txt (line 8)) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client->-r requirements.txt (line 3)) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344562b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Sheet API\n",
    "from __future__ import print_function\n",
    "\n",
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "\n",
    "# def get_dynamic_range(service, spreadsheet_id, sheet_name, starting_cell='A2'):\n",
    "#     # Get the last row with data in the specified sheet\n",
    "#     request = service.spreadsheets().values().get(spreadsheetId=spreadsheet_id, range=f'{sheet_name}!A:A')\n",
    "#     response = request.execute()\n",
    "#     values = response.get('values', [])\n",
    "\n",
    "#     if not values:\n",
    "#         print('No data found.')\n",
    "#         return None\n",
    "\n",
    "#     # Filter rows with at least one non-empty cell\n",
    "#     filtered_values = [row for row in values if any(cell.strip() for cell in row)]\n",
    "\n",
    "#     if not filtered_values:\n",
    "#         print('No non-empty rows found.')\n",
    "#         return None\n",
    "\n",
    "#     # Find the last row with data\n",
    "#     last_row = len(filtered_values)\n",
    "\n",
    "#     # Construct the dynamic range\n",
    "#     dynamic_range = f\"{sheet_name}!{starting_cell}:E{last_row}\"\n",
    "\n",
    "#     return dynamic_range\n",
    "\n",
    "# def get_all_researchers_data():\n",
    "#     SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "#     SAMPLE_SPREADSHEET_ID = '1PqIcpTPeb7_CuvTtQhb0p1OySDGArqF6auQVmz_jF8c'\n",
    "#     SHEET_NAME = 'Sheet1'\n",
    "\n",
    "#     creds = None\n",
    "#     if os.path.exists('token.json'):\n",
    "#         creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "#     if not creds or not creds.valid:\n",
    "#         if creds and creds.expired and creds.refresh_token:\n",
    "#             print(f'Token expires at: {creds.expiry}')\n",
    "#             creds.refresh(Request())\n",
    "#         else:\n",
    "#             flow = InstalledAppFlow.from_client_secrets_file(\n",
    "#                 'credentials.json', SCOPES)\n",
    "#             creds = flow.run_local_server(port=0)\n",
    "#         with open('token.json', 'w') as token:\n",
    "#             token.write(creds.to_json())\n",
    "\n",
    "#     try:\n",
    "#         service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "#         # Get the dynamic range based on the last row with data\n",
    "#         dynamic_range = get_dynamic_range(service, SAMPLE_SPREADSHEET_ID, SHEET_NAME)\n",
    "\n",
    "#         # Call the Sheets API with the dynamic range\n",
    "#         result = service.spreadsheets().values().get(spreadsheetId=SAMPLE_SPREADSHEET_ID,\n",
    "#                                                     range=dynamic_range).execute()\n",
    "#         values = result.get('values', [])\n",
    "\n",
    "#         if not values:\n",
    "#             print('No data found.')\n",
    "#             return\n",
    "\n",
    "#         all_researcher_data = []\n",
    "#         for row in values:\n",
    "#             if row:\n",
    "#                 data_records = {\n",
    "#                     \"nama\": row[0] if len(row) > 0 else '',\n",
    "#                     \"link_scholar\": row[1] if len(row) > 1 else '',\n",
    "#                     \"jabatan\": row[2] if len(row) > 2 else '',\n",
    "#                     \"profile_url\": row[3] if len(row) > 3 else ''\n",
    "#                 }\n",
    "#                 all_researcher_data.append(data_records)\n",
    "#         list_peneliti = pd.DataFrame(all_researcher_data)\n",
    "#         print(\"get data finish\")\n",
    "#         return list_peneliti\n",
    "#     except HttpError as err:\n",
    "#         print(err)\n",
    "\n",
    "# print(get_all_researchers_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711b8e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "click 1\n",
      "click 2\n",
      "click finish Dr. Efri Mardawati, S.TP., M.T.\n",
      "peneliti 1 Dr. Efri Mardawati, S.TP., M.T. selesai\n",
      "waktu scraping Dr. Efri Mardawati, S.TP., M.T. adalah 33.94662141799927 detik\n",
      "click 1\n",
      "click finish Nanang Masruchin Ph.D.\n",
      "peneliti 2 Nanang Masruchin Ph.D. selesai\n",
      "waktu scraping Nanang Masruchin Ph.D. adalah 18.010915279388428 detik\n",
      "click finish Dr. Riksfardini Annisa Ermawar, M.Bio (PB)\n",
      "peneliti 3 Dr. Riksfardini Annisa Ermawar, M.Bio (PB) selesai\n",
      "waktu scraping Dr. Riksfardini Annisa Ermawar, M.Bio (PB) adalah 2.250932455062866 detik\n",
      "click 1\n",
      "click finish Dr. Souvia Rahimah, S.TP., M.Sc.\n",
      "peneliti 4 Dr. Souvia Rahimah, S.TP., M.Sc. selesai\n",
      "waktu scraping Dr. Souvia Rahimah, S.TP., M.Sc. adalah 9.339407205581665 detik\n",
      "click 1\n",
      "click finish Dr.Siti Nurhasanah, STP., M.Si\n",
      "peneliti 5 Dr.Siti Nurhasanah, STP., M.Si selesai\n",
      "waktu scraping Dr.Siti Nurhasanah, STP., M.Si adalah 7.841315031051636 detik\n",
      "click 1\n",
      "click finish Dr. Khatarina Meldawati Pasaribu, M.Si\n",
      "peneliti 6 Dr. Khatarina Meldawati Pasaribu, M.Si selesai\n",
      "waktu scraping Dr. Khatarina Meldawati Pasaribu, M.Si adalah 6.427968740463257 detik\n",
      "click 1\n",
      "click finish Prof. Dr. Ir. Mohamad Djali, M.S.\n",
      "peneliti 7 Prof. Dr. Ir. Mohamad Djali, M.S. selesai\n",
      "waktu scraping Prof. Dr. Ir. Mohamad Djali, M.S. adalah 16.2109272480011 detik\n",
      "click 1\n",
      "click finish Bambang Nurhadi, S. T. P., M.Sc., Ph.D.\n",
      "peneliti 8 Bambang Nurhadi, S. T. P., M.Sc., Ph.D. selesai\n",
      "waktu scraping Bambang Nurhadi, S. T. P., M.Sc., Ph.D. adalah 13.179186344146729 detik\n",
      "click 1\n",
      "click finish Dr. Herlina Marta, S.T.P., M.Si.\n",
      "peneliti 9 Dr. Herlina Marta, S.T.P., M.Si. selesai\n",
      "waktu scraping Dr. Herlina Marta, S.T.P., M.Si. adalah 12.06031608581543 detik\n",
      "click 1\n",
      "click finish Dr. In-In Hanidah, S.T.P., M.Si.\n",
      "peneliti 10 Dr. In-In Hanidah, S.T.P., M.Si. selesai\n",
      "waktu scraping Dr. In-In Hanidah, S.T.P., M.Si. adalah 11.240342378616333 detik\n",
      "click 1\n",
      "click finish Dr. Made Tri Ari Penia Kresnowati, S.Si., M.T.\n",
      "peneliti 11 Dr. Made Tri Ari Penia Kresnowati, S.Si., M.T. selesai\n",
      "waktu scraping Dr. Made Tri Ari Penia Kresnowati, S.Si., M.T. adalah 16.250035762786865 detik\n",
      "click 1\n",
      "click finish Robi Andoyo, S.T.P., M.Sc., Ph.D.\n",
      "peneliti 12 Robi Andoyo, S.T.P., M.Sc., Ph.D. selesai\n",
      "waktu scraping Robi Andoyo, S.T.P., M.Sc., Ph.D. adalah 15.717214584350586 detik\n",
      "click 1\n",
      "click finish Tri Yuliana, S.Si., M.Si., Ph.D.\n",
      "peneliti 13 Tri Yuliana, S.Si., M.Si., Ph.D. selesai\n",
      "waktu scraping Tri Yuliana, S.Si., M.Si., Ph.D. adalah 15.903276920318604 detik\n",
      "click 1\n",
      "click finish Yudhi Dwi Kurniawan, Ph.D.\n",
      "peneliti 14 Yudhi Dwi Kurniawan, Ph.D. selesai\n",
      "waktu scraping Yudhi Dwi Kurniawan, Ph.D. adalah 8.279435157775879 detik\n",
      "click 1\n",
      "click finish Dr. Elazmanawati Lembong\n",
      "peneliti 15 Dr. Elazmanawati Lembong selesai\n",
      "waktu scraping Dr. Elazmanawati Lembong adalah 13.223052263259888 detik\n",
      "click 1\n",
      "click 2\n",
      "click finish Ahmad Sofyan, Ph.D.\n",
      "peneliti 16 Ahmad Sofyan, Ph.D. selesai\n",
      "waktu scraping Ahmad Sofyan, Ph.D. adalah 25.61833143234253 detik\n",
      "click 1\n",
      "click finish Dr. Muhamad Fatah Wiyatna, S.Pt., M.Si.\n",
      "peneliti 17 Dr. Muhamad Fatah Wiyatna, S.Pt., M.Si. selesai\n",
      "waktu scraping Dr. Muhamad Fatah Wiyatna, S.Pt., M.Si. adalah 9.498341083526611 detik\n",
      "click 1\n",
      "click finish Dr. Sophia Dwiratna Nur Perwitasari, S.T.P., M.T.\n",
      "peneliti 18 Dr. Sophia Dwiratna Nur Perwitasari, S.T.P., M.T. selesai\n",
      "waktu scraping Dr. Sophia Dwiratna Nur Perwitasari, S.T.P., M.T. adalah 19.585826635360718 detik\n",
      "click 1\n",
      "click finish Hendra Herdian SPt MSc\n",
      "peneliti 19 Hendra Herdian SPt MSc selesai\n",
      "waktu scraping Hendra Herdian SPt MSc adalah 13.759310483932495 detik\n",
      "click 1\n",
      "click finish Roni Maryana Ph.D.\n",
      "peneliti 20 Roni Maryana Ph.D. selesai\n",
      "waktu scraping Roni Maryana Ph.D. adalah 15.18881368637085 detik\n",
      "click 1\n",
      "click finish Dr.Awalina,M.Si\n",
      "peneliti 21 Dr.Awalina,M.Si selesai\n",
      "waktu scraping Dr.Awalina,M.Si adalah 11.44893193244934 detik\n",
      "click 1\n",
      "click finish Nova Rachmadona, Ph.D.\n",
      "peneliti 22 Nova Rachmadona, Ph.D. selesai\n",
      "waktu scraping Nova Rachmadona, Ph.D. adalah 8.494027853012085 detik\n",
      "click 1\n",
      "click finish Hana Nur Fitriana, S.Si., M.T., Ph.D\n",
      "peneliti 23 Hana Nur Fitriana, S.Si., M.T., Ph.D selesai\n",
      "waktu scraping Hana Nur Fitriana, S.Si., M.T., Ph.D adalah 7.859865665435791 detik\n",
      "click 1\n",
      "click 2\n",
      "click finish Prof. Dr. Novizar Nazir\n",
      "peneliti 24 Prof. Dr. Novizar Nazir selesai\n",
      "waktu scraping Prof. Dr. Novizar Nazir adalah 26.805917978286743 detik\n",
      "click 1\n",
      "click 2\n",
      "click finish Dr. Kasbawati, S.Si., M.Si.\n",
      "peneliti 25 Dr. Kasbawati, S.Si., M.Si. selesai\n",
      "waktu scraping Dr. Kasbawati, S.Si., M.Si. adalah 35.08118772506714 detik\n",
      "click 1\n",
      "click 2\n",
      "click 3\n",
      "click finish Prof. Ir. Yazid Bindar, M.Sc., Ph.D., IPM\n",
      "peneliti 26 Prof. Ir. Yazid Bindar, M.Sc., Ph.D., IPM selesai\n",
      "waktu scraping Prof. Ir. Yazid Bindar, M.Sc., Ph.D., IPM adalah 36.3840115070343 detik\n",
      "click 1\n",
      "click finish Devi Maulida Rahmah, S.T.P., M.T., Ph.D.\n",
      "peneliti 27 Devi Maulida Rahmah, S.T.P., M.T., Ph.D. selesai\n",
      "waktu scraping Devi Maulida Rahmah, S.T.P., M.T., Ph.D. adalah 10.151979684829712 detik\n",
      "click 1\n",
      "click 2\n",
      "click finish Dr. Ir. Edy Suryadi, M.T.\n",
      "peneliti 28 Dr. Ir. Edy Suryadi, M.T. selesai\n",
      "waktu scraping Dr. Ir. Edy Suryadi, M.T. adalah 20.2569100856781 detik\n",
      "click 1\n",
      "click 2\n",
      "click finish Sri Suhartini, S.T.P., M.Env.Mgt., Ph.D.\n",
      "peneliti 29 Sri Suhartini, S.T.P., M.Env.Mgt., Ph.D. selesai\n",
      "waktu scraping Sri Suhartini, S.T.P., M.Env.Mgt., Ph.D. adalah 19.737359523773193 detik\n",
      "click 1\n",
      "click 2\n",
      "click finish Dr. Muhammad Adly Rahandi Lubis\n",
      "peneliti 30 Dr. Muhammad Adly Rahandi Lubis selesai\n",
      "waktu scraping Dr. Muhammad Adly Rahandi Lubis adalah 28.468498706817627 detik\n",
      "click 1\n",
      "click finish Dr. Melbi Mahardika, S.T.\n",
      "peneliti 31 Dr. Melbi Mahardika, S.T. selesai\n",
      "waktu scraping Dr. Melbi Mahardika, S.T. adalah 10.948657989501953 detik\n",
      "click 1\n",
      "click finish Prof. Dr. Ir. Myrtha Karina, M.Agr.\n",
      "peneliti 32 Prof. Dr. Ir. Myrtha Karina, M.Agr. selesai\n",
      "waktu scraping Prof. Dr. Ir. Myrtha Karina, M.Agr. adalah 12.158888816833496 detik\n",
      "click 1\n",
      "click finish Dr. Eng. Ir. Jenny Rizkiana, ST, MT, IPP\n",
      "peneliti 33 Dr. Eng. Ir. Jenny Rizkiana, ST, MT, IPP selesai\n",
      "waktu scraping Dr. Eng. Ir. Jenny Rizkiana, ST, MT, IPP adalah 13.521268367767334 detik\n",
      "click 1\n",
      "click finish Dr. Akbar Hanif Dawam Abdullah, M.T.\n",
      "peneliti 34 Dr. Akbar Hanif Dawam Abdullah, M.T. selesai\n",
      "waktu scraping Dr. Akbar Hanif Dawam Abdullah, M.T. adalah 9.683376550674438 detik\n",
      "click 1\n",
      "click finish Dr. S. Rosalinda, S.T., M.T.\n",
      "peneliti 35 Dr. S. Rosalinda, S.T., M.T. selesai\n",
      "waktu scraping Dr. S. Rosalinda, S.T., M.T. adalah 9.157472610473633 detik\n",
      "click finish Dr. Yeyen Nurhamiyah, S.Si.\n",
      "peneliti 36 Dr. Yeyen Nurhamiyah, S.Si. selesai\n",
      "waktu scraping Dr. Yeyen Nurhamiyah, S.Si. adalah 5.132519006729126 detik\n"
     ]
    }
   ],
   "source": [
    "# Scrapping\n",
    "\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller_fix\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver import ChromeOptions  # for suppressing the browser\n",
    "\n",
    "\n",
    "csv_file = pd.read_csv(\"https://raw.githubusercontent.com/pkr-br/scholar-scraping/main/list_peneliti.csv\")\n",
    "list_peneliti = csv_file\n",
    "list_peneliti = list_peneliti[list_peneliti['link_scholar'].notna()]\n",
    "added_link = \"&view_op=list_works&sortby=pubdate\"\n",
    "list_peneliti[\"updated_link_scholar\"] = [i+added_link for i in list_peneliti['link_scholar']]\n",
    "chromedriver_autoinstaller_fix.install()\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless=new\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "all_publications = {}\n",
    "for index, row in list_peneliti.iterrows():\n",
    "    start_scrap_one = time.time()\n",
    "    nama_peneliti = row[\"nama\"]\n",
    "    URL = row[\"updated_link_scholar\"]\n",
    "    driver.get(URL)\n",
    "    driver.implicitly_wait(2)\n",
    "\n",
    "    for i in range(5):\n",
    "        btn = driver.find_elements(By.XPATH , '//button[@id=\"gsc_bpf_more\"]')[0]\n",
    "        disabled = btn.get_attribute(\"disabled\")\n",
    "        if not disabled:\n",
    "            btn.click()\n",
    "            time.sleep(3)\n",
    "            print(\"click \" + str(i + 1))\n",
    "        elif disabled:\n",
    "            break\n",
    "    print(\"click finish \" + nama_peneliti)\n",
    "\n",
    "#     Extract h-index\n",
    "    index_table = driver.find_element(By.ID, \"gsc_rsb_st\")\n",
    "    h_index_row = index_table.find_elements(By.TAG_NAME, \"tr\")[2]\n",
    "    h_index = h_index_row.find_element(By.CLASS_NAME, \"gsc_rsb_std\").text\n",
    "    \n",
    "#     Extract specialities\n",
    "    specialities = driver.find_elements(By.CLASS_NAME, \"gsc_prf_inta.gs_ibl\")\n",
    "    # Check if specialities exist\n",
    "    if specialities:\n",
    "        # If specialities exist, extract text from each element and store it in a list\n",
    "        speciality_list = [element.text for element in specialities]\n",
    "    else:\n",
    "        speciality_list = []\n",
    "    \n",
    "\n",
    "    publications = driver.find_elements(By.CLASS_NAME, \"gsc_a_tr\")\n",
    "    publications_list = []\n",
    "    for publication in publications:\n",
    "        data_list = {}\n",
    "        title = publication.find_element(By.CLASS_NAME, \"gsc_a_at\").text\n",
    "        data_list[\"title\"] = str(title)\n",
    "        link = publication.find_element(By.CLASS_NAME, \"gsc_a_at\").get_attribute(\"href\")\n",
    "        data_list['link'] = str(link)\n",
    "        year = publication.find_element(By.CLASS_NAME, \"gsc_a_y\").text\n",
    "        if(year != \"\"):\n",
    "            data_list[\"year\"] = int(year)\n",
    "        citate = publication.find_element(By.CLASS_NAME, \"gsc_a_c\").text\n",
    "        if \"\\n*\" in citate:\n",
    "            citate = citate.replace(\"\\n*\", \"\")\n",
    "        if(citate != \"\"):\n",
    "            data_list[\"cited by\"] = int(citate)\n",
    "        else :\n",
    "            data_list[\"cited by\"] = 0\n",
    "        authors = publication.find_element(By.CLASS_NAME, \"gs_gray\").text\n",
    "        journal = publication.find_elements(By.CLASS_NAME, \"gs_gray\")[1].text\n",
    "        if(journal == \"\"):\n",
    "            journal = \"-\"\n",
    "        data_list[\"journal\"] = str(journal)\n",
    "        data_list[\"authors\"] = str(authors)\n",
    "\n",
    "        publications_list.append(data_list)\n",
    "    all_publications[nama_peneliti] = {\n",
    "        \"name\": nama_peneliti,\n",
    "        \"publications\": publications_list,\n",
    "        \"specialities\": speciality_list,\n",
    "        \"h_index\": h_index\n",
    "    }\n",
    "    print(\"peneliti \" + str(index + 1)+\" \"+ nama_peneliti + \" selesai\")\n",
    "    end_scrap_one = time.time()\n",
    "    scrap_time = end_scrap_one - start_scrap_one\n",
    "    print(\"waktu scraping \" + nama_peneliti + \" adalah \" + str(scrap_time) + \" detik\")\n",
    "\n",
    "# Specify the file path where you want to save the JSON file\n",
    "file_path = 'data_publications.json'\n",
    "\n",
    "# Write the dictionary data to a JSON file\n",
    "with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(all_publications, json_file, indent=2, ensure_ascii=False)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24e98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2763\n",
      "                                                 nama  \\\n",
      "0                     Dr. Efri Mardawati, S.TP., M.T.   \n",
      "1                              Nanang Masruchin Ph.D.   \n",
      "2          Dr. Riksfardini Annisa Ermawar, M.Bio (PB)   \n",
      "3                    Dr. Souvia Rahimah, S.TP., M.Sc.   \n",
      "4                      Dr.Siti Nurhasanah, STP., M.Si   \n",
      "5              Dr. Khatarina Meldawati Pasaribu, M.Si   \n",
      "6                   Prof. Dr. Ir. Mohamad Djali, M.S.   \n",
      "7             Bambang Nurhadi, S. T. P., M.Sc., Ph.D.   \n",
      "8                    Dr. Herlina Marta, S.T.P., M.Si.   \n",
      "9                    Dr. In-In Hanidah, S.T.P., M.Si.   \n",
      "10     Dr. Made Tri Ari Penia Kresnowati, S.Si., M.T.   \n",
      "11                  Robi Andoyo, S.T.P., M.Sc., Ph.D.   \n",
      "12                   Tri Yuliana, S.Si., M.Si., Ph.D.   \n",
      "13                         Yudhi Dwi Kurniawan, Ph.D.   \n",
      "14                           Dr. Elazmanawati Lembong   \n",
      "15                                Ahmad Sofyan, Ph.D.   \n",
      "16            Dr. Muhamad Fatah Wiyatna, S.Pt., M.Si.   \n",
      "17  Dr. Sophia Dwiratna Nur Perwitasari, S.T.P., M.T.   \n",
      "18                             Hendra Herdian SPt MSc   \n",
      "19                                 Roni Maryana Ph.D.   \n",
      "20                                    Dr.Awalina,M.Si   \n",
      "21                             Nova Rachmadona, Ph.D.   \n",
      "22               Hana Nur Fitriana, S.Si., M.T., Ph.D   \n",
      "23                            Prof. Dr. Novizar Nazir   \n",
      "24                        Dr. Kasbawati, S.Si., M.Si.   \n",
      "25          Prof. Ir. Yazid Bindar, M.Sc., Ph.D., IPM   \n",
      "26           Devi Maulida Rahmah, S.T.P., M.T., Ph.D.   \n",
      "27                          Dr. Ir. Edy Suryadi, M.T.   \n",
      "28           Sri Suhartini, S.T.P., M.Env.Mgt., Ph.D.   \n",
      "29                    Dr. Muhammad Adly Rahandi Lubis   \n",
      "30                          Dr. Melbi Mahardika, S.T.   \n",
      "31                Prof. Dr. Ir. Myrtha Karina, M.Agr.   \n",
      "32           Dr. Eng. Ir. Jenny Rizkiana, ST, MT, IPP   \n",
      "33               Dr. Akbar Hanif Dawam Abdullah, M.T.   \n",
      "34                       Dr. S. Rosalinda, S.T., M.T.   \n",
      "35                        Dr. Yeyen Nurhamiyah, S.Si.   \n",
      "\n",
      "                                         link_scholar  \\\n",
      "0   https://scholar.google.co.id/citations?user=Hm...   \n",
      "1   https://scholar.google.co.kr/citations?user=B4...   \n",
      "2   https://scholar.google.com/citations?user=Kit_...   \n",
      "3   https://scholar.google.co.id/citations?user=28...   \n",
      "4   https://scholar.google.com/citations?user=H3rx...   \n",
      "5   https://scholar.google.com/citations?user=sonl...   \n",
      "6   https://scholar.google.com/citations?user=6UUm...   \n",
      "7   https://scholar.google.com/citations?hl=id&use...   \n",
      "8   https://scholar.google.com/citations?hl=id&use...   \n",
      "9   https://scholar.google.com/citations?hl=id&use...   \n",
      "10  https://scholar.google.com/citations?hl=id&use...   \n",
      "11  https://scholar.google.com/citations?hl=id&use...   \n",
      "12  https://scholar.google.com/citations?hl=id&use...   \n",
      "13  https://scholar.google.com/citations?hl=id&use...   \n",
      "14  https://scholar.google.com/citations?hl=id&use...   \n",
      "15  https://scholar.google.com/citations?hl=id&use...   \n",
      "16  https://scholar.google.com/citations?hl=id&use...   \n",
      "17  https://scholar.google.com/citations?hl=id&use...   \n",
      "18  https://scholar.google.com/citations?hl=id&use...   \n",
      "19  https://scholar.google.co.jp/citations?user=qx...   \n",
      "20  https://scholar.google.co.id/citations?user=55...   \n",
      "21  https://scholar.google.co.id/citations?user=Cy...   \n",
      "22  https://scholar.google.com/citations?hl=en&use...   \n",
      "23  https://scholar.google.co.id/citations?user=no...   \n",
      "24  https://scholar.google.co.id/citations?user=KX...   \n",
      "25  https://scholar.google.com/citations?hl=id&use...   \n",
      "26  https://scholar.google.com/citations?hl=id&use...   \n",
      "27  https://scholar.google.com/citations?hl=id&use...   \n",
      "28  https://scholar.google.com/citations?hl=id&use...   \n",
      "29  https://scholar.google.com/citations?user=GYNS...   \n",
      "30  https://scholar.google.com/citations?user=VuKK...   \n",
      "31  https://scholar.google.com/citations?user=NHbJ...   \n",
      "32  https://scholar.google.com/citations?user=fpF0...   \n",
      "33  https://scholar.google.com/citations?hl=id&use...   \n",
      "34  https://scholar.google.com/citations?user=Jnq-...   \n",
      "35  https://scholar.google.com/citations?hl=id&use...   \n",
      "\n",
      "                                    jabatan  \\\n",
      "0              Ketua Pusat Kolaborasi Riset   \n",
      "1            Manager Pusat Kolaborasi Riset   \n",
      "2   Ketua Riset Pangan dan Kesehatan PKR BR   \n",
      "3   Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "4   Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "5   Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "6   Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "7   Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "8   Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "9   Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "10  Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "11  Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "12  Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "13  Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "14  Staff Riset Pangan dan Kesehatan PKR BR   \n",
      "15                        Staff Riset Pakan   \n",
      "16                        Ketua Riset Pakan   \n",
      "17                        Staff Riset Pakan   \n",
      "18                        Staff Riset Pakan   \n",
      "19                    Ketua Riset Bioenergy   \n",
      "20                    Staff Riset Bioenergy   \n",
      "21                    Staff Riset Bioenergy   \n",
      "22                    Staff Riset Bioenergy   \n",
      "23                    Staff Riset Bioenergy   \n",
      "24                    Staff Riset Bioenergy   \n",
      "25                    Staff Riset Bioenergy   \n",
      "26                    Staff Riset Bioenergy   \n",
      "27                    Staff Riset Bioenergy   \n",
      "28                    Staff Riset Bioenergy   \n",
      "29                  Ketua Riset Biomaterial   \n",
      "30                  Staff Riset Biomaterial   \n",
      "31                  Staff Riset Biomaterial   \n",
      "32                  Staff Riset Biomaterial   \n",
      "33                  Staff Riset Biomaterial   \n",
      "34                  Staff Riset Biomaterial   \n",
      "35                  Staff Riset Biomaterial   \n",
      "\n",
      "                                      halaman_profile  \\\n",
      "0   https://www.biomassbiorefinery.org/dr-efri-mar...   \n",
      "1   https://www.biomassbiorefinery.org/nanang-masr...   \n",
      "2   https://www.biomassbiorefinery.org/dr-riksfard...   \n",
      "3   https://www.biomassbiorefinery.org/dr-souvia-r...   \n",
      "4   https://www.biomassbiorefinery.org/dr-siti-nur...   \n",
      "5   https://www.biomassbiorefinery.org/dr-khatarin...   \n",
      "6   http://localhost/biomass/homedir/public_html/p...   \n",
      "7   http://localhost/biomass/homedir/public_html/b...   \n",
      "8   http://localhost/biomass/homedir/public_html/d...   \n",
      "9   http://localhost/biomass/homedir/public_html/d...   \n",
      "10  http://localhost/biomass/homedir/public_html/d...   \n",
      "11  http://localhost/biomass/homedir/public_html/r...   \n",
      "12  http://localhost/biomass/homedir/public_html/t...   \n",
      "13  http://localhost/biomass/homedir/public_html/y...   \n",
      "14  http://localhost/biomass/homedir/public_html/d...   \n",
      "15  http://localhost/biomass/homedir/public_html/a...   \n",
      "16  http://localhost/biomass/homedir/public_html/d...   \n",
      "17  http://localhost/biomass/homedir/public_html/d...   \n",
      "18  http://localhost/biomass/homedir/public_html/h...   \n",
      "19  https://www.biomassbiorefinery.org/roni-maryan...   \n",
      "20  https://www.biomassbiorefinery.org/dr-awalinam...   \n",
      "21  https://www.biomassbiorefinery.org/nova-rachma...   \n",
      "22  https://www.biomassbiorefinery.org/hana-nur-fi...   \n",
      "23  https://www.biomassbiorefinery.org/prof-dr-nov...   \n",
      "24  https://www.biomassbiorefinery.org/dr-kasbawat...   \n",
      "25  http://localhost/biomass/homedir/public_html/p...   \n",
      "26  http://localhost/biomass/homedir/public_html/d...   \n",
      "27  http://localhost/biomass/homedir/public_html/d...   \n",
      "28  http://localhost/biomass/homedir/public_html/s...   \n",
      "29  http://localhost/biomass/homedir/public_html/d...   \n",
      "30  https://www.biomassbiorefinery.org/dr-melbi-ma...   \n",
      "31  https://www.biomassbiorefinery.org/prof-dr-ir-...   \n",
      "32  https://www.biomassbiorefinery.org/dr-eng-ir-j...   \n",
      "33  http://localhost/biomass/homedir/public_html/d...   \n",
      "34  http://localhost/biomass/homedir/public_html/d...   \n",
      "35  http://localhost/biomass/homedir/public_html/d...   \n",
      "\n",
      "                                 updated_link_scholar  \n",
      "0   https://scholar.google.co.id/citations?user=Hm...  \n",
      "1   https://scholar.google.co.kr/citations?user=B4...  \n",
      "2   https://scholar.google.com/citations?user=Kit_...  \n",
      "3   https://scholar.google.co.id/citations?user=28...  \n",
      "4   https://scholar.google.com/citations?user=H3rx...  \n",
      "5   https://scholar.google.com/citations?user=sonl...  \n",
      "6   https://scholar.google.com/citations?user=6UUm...  \n",
      "7   https://scholar.google.com/citations?hl=id&use...  \n",
      "8   https://scholar.google.com/citations?hl=id&use...  \n",
      "9   https://scholar.google.com/citations?hl=id&use...  \n",
      "10  https://scholar.google.com/citations?hl=id&use...  \n",
      "11  https://scholar.google.com/citations?hl=id&use...  \n",
      "12  https://scholar.google.com/citations?hl=id&use...  \n",
      "13  https://scholar.google.com/citations?hl=id&use...  \n",
      "14  https://scholar.google.com/citations?hl=id&use...  \n",
      "15  https://scholar.google.com/citations?hl=id&use...  \n",
      "16  https://scholar.google.com/citations?hl=id&use...  \n",
      "17  https://scholar.google.com/citations?hl=id&use...  \n",
      "18  https://scholar.google.com/citations?hl=id&use...  \n",
      "19  https://scholar.google.co.jp/citations?user=qx...  \n",
      "20  https://scholar.google.co.id/citations?user=55...  \n",
      "21  https://scholar.google.co.id/citations?user=Cy...  \n",
      "22  https://scholar.google.com/citations?hl=en&use...  \n",
      "23  https://scholar.google.co.id/citations?user=no...  \n",
      "24  https://scholar.google.co.id/citations?user=KX...  \n",
      "25  https://scholar.google.com/citations?hl=id&use...  \n",
      "26  https://scholar.google.com/citations?hl=id&use...  \n",
      "27  https://scholar.google.com/citations?hl=id&use...  \n",
      "28  https://scholar.google.com/citations?hl=id&use...  \n",
      "29  https://scholar.google.com/citations?user=GYNS...  \n",
      "30  https://scholar.google.com/citations?user=VuKK...  \n",
      "31  https://scholar.google.com/citations?user=NHbJ...  \n",
      "32  https://scholar.google.com/citations?user=fpF0...  \n",
      "33  https://scholar.google.com/citations?hl=id&use...  \n",
      "34  https://scholar.google.com/citations?user=Jnq-...  \n",
      "35  https://scholar.google.com/citations?hl=id&use...  \n"
     ]
    }
   ],
   "source": [
    "total_publications = sum(len(author_data[\"publications\"]) for author_data in all_publications.values())\n",
    "print(total_publications)\n",
    "print(list_peneliti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff968b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Github\n",
    "username = 'pkr-br'\n",
    "repository = 'scholar-scraping'\n",
    "file_path = 'data_publications.json'\n",
    "\n",
    "access_token = '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'\n",
    "\n",
    "from github import Github\n",
    "\n",
    "# Authentication is defined via github.Auth\n",
    "from github import Auth\n",
    "\n",
    "# using an access token\n",
    "auth = Auth.Token(access_token)\n",
    "\n",
    "\n",
    "# Public Web Github\n",
    "g = Github(auth=auth)\n",
    "\n",
    "repo = g.get_repo(f'{username}/{repository}')\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Format the date as \"dd-mm-yyyy\"\n",
    "formatted_date = current_date.strftime(\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "updated_file_path = 'data_publications.json'\n",
    "\n",
    "with open(updated_file_path, 'r', encoding='utf-8') as file:\n",
    "    updated_json_data = file.read()\n",
    "\n",
    "# Update the file in the repository\n",
    "commit_message = f'Updated data at {formatted_date}'\n",
    "file = repo.get_contents(file_path)\n",
    "updated_file = repo.update_file(file_path, commit_message, updated_json_data, file.sha)\n",
    "\n",
    "if updated_file:\n",
    "    print('File updated successfully.')\n",
    "else:\n",
    "    print('Failed to update the file.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87781470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564.3358273506165\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()  # Record the end time\n",
    "elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68387363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
